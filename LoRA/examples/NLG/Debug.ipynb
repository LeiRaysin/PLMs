{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Git\\LoRA\\examples\\NLG\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "%cd D:\\Code\\Git\\LoRA\\examples\\NLG\n",
    "# !python -m pip install --upgrade pip\n",
    "!python -m pip install -r D:\\Code\\Git\\LoRA\\examples\\NLG\\requirement.txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T06:00:31.301044500Z",
     "start_time": "2024-07-12T05:48:22.630051Z"
    }
   },
   "id": "74f98a0ae917015f"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.19\n",
      "2.3.1+cu118\n",
      "True\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch._C' has no attribute '_nccl_version'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available())\n\u001B[0;32m      5\u001B[0m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mset_device(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnccl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mversion\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\cuda\\nccl.py:35\u001B[0m, in \u001B[0;36mversion\u001B[1;34m()\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mversion\u001B[39m():\n\u001B[1;32m---> 35\u001B[0m     ver \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nccl_version\u001B[49m()\n\u001B[0;32m     36\u001B[0m     major \u001B[38;5;241m=\u001B[39m ver \u001B[38;5;241m>>\u001B[39m \u001B[38;5;241m32\u001B[39m\n\u001B[0;32m     37\u001B[0m     minor \u001B[38;5;241m=\u001B[39m (ver \u001B[38;5;241m>>\u001B[39m \u001B[38;5;241m16\u001B[39m) \u001B[38;5;241m&\u001B[39m \u001B[38;5;241m65535\u001B[39m\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'torch._C' has no attribute '_nccl_version'"
     ]
    }
   ],
   "source": [
    "!python -V\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "torch.cuda.set_device(0)\n",
    "print(torch.cuda.nccl.version())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T06:24:19.442429Z",
     "start_time": "2024-07-12T06:24:19.354268Z"
    }
   },
   "id": "a3ff947eb0fb8e7c"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0712 14:40:43.872365 29904 torch\\distributed\\elastic\\multiprocessing\\redirects.py:27] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "[W socket.cpp:697] [c10d] The client socket has failed to connect to [kubernetes.docker.internal]:29500 (system error: 10049 - 在其上下文中，该请求的地址无效。).\n",
      "usage: gpt2_ft.py [-h] [--lr LR] [--weight_decay WEIGHT_DECAY]\n",
      "                  [--correct_bias] [--adam_epislon ADAM_EPISLON]\n",
      "                  [--no_decay_bias] [--adam_beta1 ADAM_BETA1]\n",
      "                  [--adam_beta2 ADAM_BETA2]\n",
      "                  [--scheduler {cosine,inv_sqrt,dev_perf,constant,linear,cycle}]\n",
      "                  [--max_step MAX_STEP] [--max_epoch MAX_EPOCH]\n",
      "                  [--warmup_step WARMUP_STEP] [--i_steps I_STEPS]\n",
      "                  [--i_lrs I_LRS] --train_data TRAIN_DATA --valid_data\n",
      "                  VALID_DATA [--train_batch_size TRAIN_BATCH_SIZE]\n",
      "                  [--valid_batch_size VALID_BATCH_SIZE] [--grad_acc GRAD_ACC]\n",
      "                  [--clip CLIP] [--seq_len SEQ_LEN]\n",
      "                  [--model_card {gpt2.sm,gpt2.md,gpt2.lg}]\n",
      "                  [--init_checkpoint INIT_CHECKPOINT] [--fp16]\n",
      "                  [--log_interval LOG_INTERVAL]\n",
      "                  [--eval_interval EVAL_INTERVAL]\n",
      "                  [--save_interval SAVE_INTERVAL] [--work_dir WORK_DIR]\n",
      "                  [--lora_dim LORA_DIM] [--lora_alpha LORA_ALPHA]\n",
      "                  [--obj {jlm,clm}] [--lora_dropout LORA_DROPOUT]\n",
      "                  [--label_smooth LABEL_SMOOTH]\n",
      "                  [--roll_interval ROLL_INTERVAL] [--roll_lr ROLL_LR]\n",
      "                  [--roll_step ROLL_STEP] [--eval_epoch EVAL_EPOCH]\n",
      "gpt2_ft.py: error: unrecognized arguments: --platform local --random_seed 110\n",
      "E0712 14:40:48.951160 29904 torch\\distributed\\elastic\\multiprocessing\\api.py:826] failed (exitcode: 2) local_rank: 0 (pid: 22156) of binary: D:\\Code\\Envs\\PLMs\\python.exe\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Code\\Envs\\PLMs\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"D:\\Code\\Envs\\PLMs\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Rezun\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\distributed\\run.py\", line 883, in <module>\n",
      "    main()\n",
      "  File \"C:\\Users\\Rezun\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\distributed\\elastic\\multiprocessing\\errors\\__init__.py\", line 347, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Rezun\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\distributed\\run.py\", line 879, in main\n",
      "    run(args)\n",
      "  File \"C:\\Users\\Rezun\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\distributed\\run.py\", line 870, in run\n",
      "    elastic_launch(\n",
      "  File \"C:\\Users\\Rezun\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\distributed\\launcher\\api.py\", line 132, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"C:\\Users\\Rezun\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\distributed\\launcher\\api.py\", line 263, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "src/gpt2_ft.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2024-07-12_14:40:48\n",
      "  host      : DESKTOP-REZUN\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 2 (pid: 22156)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!python -m torch.distributed.run --nproc_per_node=1 src/gpt2_ft.py \\\n",
    "    --train_data ./data/e2e/train.jsonl \\\n",
    "    --valid_data ./data/e2e/valid.jsonl \\\n",
    "    --train_batch_size 8 \\\n",
    "    --grad_acc 1 \\\n",
    "    --valid_batch_size 4 \\\n",
    "    --seq_len 512 \\\n",
    "    --model_card gpt2.md \\\n",
    "    --init_checkpoint ./pretrained_checkpoints/gpt2-medium-pytorch_model.bin \\\n",
    "    --platform local \\\n",
    "    --clip 0.0 \\\n",
    "    --lr 0.0002 \\\n",
    "    --weight_decay 0.01 \\\n",
    "    --correct_bias \\\n",
    "    --adam_beta2 0.999 \\\n",
    "    --scheduler linear \\\n",
    "    --warmup_step 500 \\\n",
    "    --max_epoch 5 \\\n",
    "    --save_interval 1000 \\\n",
    "    --lora_dim 4 \\\n",
    "    --lora_alpha 32 \\\n",
    "    --lora_dropout 0.1 \\\n",
    "    --label_smooth 0.1 \\\n",
    "    --work_dir ./trained_models/GPT2_M/e2e \\\n",
    "    --random_seed 110"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T06:40:49.685300700Z",
     "start_time": "2024-07-12T06:40:41.870341Z"
    }
   },
   "id": "daec3694eb424afb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "623a390950e7c8d3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
